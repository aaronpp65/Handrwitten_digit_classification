{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handwritten_digits_NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/aaronpp65/Handrwitten_digit_classification/blob/master/handwritten_digits_NN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "3Vpo95mkJWnC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows=10\n",
        "pd.options.display.float_format='{:.1f}'.format\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e8VyNqEyJg41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe=pd.read_csv(\"https://storage.googleapis.com/mledu-datasets/mnist_train_small.csv\",sep=\",\",header=None)\n",
        "\n",
        "mnist_dataframe = mnist_dataframe.head(10000)\n",
        "\n",
        "mnist_dataframe = mnist_dataframe.reindex(np.random.permutation(mnist_dataframe.index))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WxMGv9lvJkzS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create labels and features\n",
        "def labels_and_features(dataset):\n",
        "\t\n",
        "\tlabels = dataset[0]\n",
        "\t\n",
        "\tfeatures = dataset.loc[:,1:784]\n",
        "\tfeatures = features/255\n",
        "\t\n",
        "\treturn labels, features\n",
        "\t\n",
        "training_targets,training_examples = labels_and_features(mnist_dataframe[:7500])\n",
        "\n",
        "validation_targets,validation_examples = labels_and_features(mnist_dataframe[7500:10000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "23e7Nn_6Ucsr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create input function for training\n",
        "def train_input_fn(features,labels,batch_size,num_epochs = None,shuffle = True):\n",
        "  \n",
        "  def _input_fn(num_epochs=None, shuffle=True):\n",
        "    \n",
        "    idx = np.random.permutation(features.index)\n",
        "    raw_features = {\"pixels\":features.reindex(idx)}\n",
        "    raw_targets = np.array(labels[idx])\n",
        "    \n",
        "    ds = Dataset.from_tensor_slices((raw_features,raw_targets))\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "      \n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6XOsUpOpdNrb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create input function for Prediction\n",
        "\n",
        "def predict_input_fn(features, labels, batch_size):\n",
        "   \n",
        "  def _input_fn():\n",
        "    \n",
        "    raw_features = {\"pixels\": features.values}\n",
        "    raw_targets = np.array(labels)\n",
        "    \n",
        "    ds = Dataset.from_tensor_slices((raw_features, raw_targets))\n",
        "    ds = ds.batch(batch_size)\n",
        "    \n",
        "        \n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZELolvt8Gymq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_NN(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    hidden_units,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \n",
        " \n",
        "\n",
        "  periods = 10\n",
        " \n",
        "  steps_per_period = steps / periods  \n",
        "  \n",
        "  predict_training_input_fn = predict_input_fn(training_examples, training_targets, batch_size)\n",
        "  \n",
        "  predict_validation_input_fn = predict_input_fn(validation_examples, validation_targets, batch_size)\n",
        "  \n",
        "  training_input_fn = train_input_fn(training_examples, training_targets, batch_size)\n",
        "  \n",
        "#creating feature columns\n",
        "  \n",
        "  feature_columns = [tf.feature_column.numeric_column('pixels', shape=784)]\n",
        "  \n",
        "#creating NN\n",
        "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.DNNClassifier(\n",
        "      feature_columns=feature_columns,\n",
        "      n_classes=10,\n",
        "      hidden_units=hidden_units,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.contrib.learn.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "#Training \n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss error (on validation data):\")\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
        "\n",
        "  \n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wqeKYOCXDjNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "60175560-8bac-4972-87f8-58eb8d5b0e34"
      },
      "cell_type": "code",
      "source": [
        "classifier = train_NN(\n",
        "    learning_rate=0.05,\n",
        "    steps=1000,\n",
        "    batch_size=30,\n",
        "    hidden_units=[100, 100],\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "LogLoss error (on validation data):\n",
            "  period 00 : 4.59\n",
            "  period 01 : 3.34\n",
            "  period 02 : 3.85\n",
            "  period 03 : 2.65\n",
            "  period 04 : 2.62\n",
            "  period 05 : 2.79\n",
            "  period 06 : 2.04\n",
            "  period 07 : 1.96\n",
            "  period 08 : 1.98\n",
            "  period 09 : 1.96\n",
            "Model training finished.\n",
            "Final accuracy (on validation data): 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dG14Dit4Dogk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "1c16295c-4fbf-4761-f8d4-15d761cace09"
      },
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "\n",
        "mnist_test_dataframe = pd.read_csv(\n",
        "  \"https://storage.googleapis.com/mledu-datasets/mnist_test.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "test_targets, test_examples = labels_and_features(mnist_test_dataframe)\n",
        "predict_test_input_fn = predict_input_fn(test_examples, test_targets, batch_size=100)\n",
        "\n",
        "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
        "test_predictions = np.array([item['class_ids'][0] for item in test_predictions])\n",
        "  \n",
        "accuracy = metrics.accuracy_score(test_targets, test_predictions)\n",
        "print(\"Accuracy on test data: %0.2f \\n\" % accuracy)\n",
        "\n",
        "rand_example = np.random.choice(test_examples.index)\n",
        "\n",
        "print(\"Random handwritten digit : %1d \\n\" % test_targets.values[rand_example])\n",
        "print(\"Prediction : %1d\" % test_predictions[rand_example])\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data: 0.95 \n",
            "\n",
            "Random handwritten digit 9 \n",
            "\n",
            "Prediction 9\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}